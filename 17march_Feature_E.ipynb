{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae3ff4e-1473-49e2-a81c-1eb2978a4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
    "#Ans.\n",
    "#Missing values can occur for various reasons, such as data entry errors, system malfunctions, or non-response by participants. \n",
    "#It is essential to handle missing values because they can lead to biased estimates, reduce the representativeness of the sample, and affect the accuracy of the analysis.\n",
    "\n",
    "#Some algorithms that are not affected by missing values include:Decision trees, Random forests, Support vector machines, K-nearest neighbors, Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93c11e0-5f2d-462c-85f2-c6f2a184f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations before pairwise deletion: 891\n",
      "Number of observations after pairwise deletion: 183\n",
      "Number of missing values before mean imputation: 0\n",
      "Number of missing values after mean imputation: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6166/599460480.py:20: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df_mean = df.fillna(df.mean())\n"
     ]
    }
   ],
   "source": [
    "#Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
    "#Ans.\n",
    "#Deletion methods: Deletion methods involve removing observations or variables with missing values. \n",
    "#There are two types of deletion methods: Listwise deletion, Pairwise deletion\n",
    "import pandas as pd\n",
    "# load dataset with missing values\n",
    "df = pd.read_csv('train.csv')\n",
    "# use pairwise deletion\n",
    "df_pairwise = df.dropna()\n",
    "# print the number of observations before and after pairwise deletion\n",
    "print(\"Number of observations before pairwise deletion:\", len(df))\n",
    "print(\"Number of observations after pairwise deletion:\", len(df_pairwise))\n",
    "\n",
    "#Imputation methods: Imputation methods involve filling in the missing values with plausible values. \n",
    "#There are several types of imputation methods: Mean imputation, Regression imputation, Multiple imputation\n",
    "import pandas as pd\n",
    "# load dataset with missing values\n",
    "df = pd.read_csv('data.csv')\n",
    "# use mean imputation\n",
    "df_mean = df.fillna(df.mean())\n",
    "# print the number of missing values before and after mean imputation\n",
    "print(\"Number of missing values before mean imputation:\", df.isna().sum().sum())\n",
    "print(\"Number of missing values after mean imputation:\", df_mean.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921a9685-b3d5-4430-897d-19ed74424ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "#Ans.\n",
    "#Imbalanced data refers to a dataset where the classes or categories are not represented equally. For example, a dataset might have 90% of the observations in one class and only 10% in another. \n",
    "#Imbalanced data can be a problem because many machine learning algorithms are designed to assume that the classes are balanced. \n",
    "#This can lead to biased models that perform poorly on the minority class.\n",
    "\n",
    "#If imbalanced data is not handled, the resulting models may have poor predictive performance on the minority class, which is often the class of interest. \n",
    "#This can result in missed opportunities for identifying important patterns or anomalies in the data.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d079bf-02bb-450d-bf23-d5440d69c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "#Ans.\n",
    "#Imbalanced data refers to a dataset where the classes or categories are not represented equally. For example, a dataset might have 90% of the observations in one class and only 10% in another. \n",
    "#Imbalanced data can be a problem because many machine learning algorithms are designed to assume that the classes are balanced. \n",
    "#This can lead to biased models that perform poorly on the minority class.\n",
    "\n",
    "#If imbalanced data is not handled, the resulting models may have poor predictive performance on the minority class, which is often the class of interest. \n",
    "#This can result in missed opportunities for identifying important patterns or anomalies in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5435546e-5eca-4c3d-a38c-f7519c7befdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required.\n",
    "#Ans.\n",
    "#Up-sampling and down-sampling are techniques used to handle imbalanced data in a dataset.\n",
    "#Down-sampling involves reducing the number of observations in the majority class to balance it with the minority class. \n",
    "#For example, if we have a dataset with 1000 observations and 900 of them belong to class A and 100 belong to class B, we can down-sample class A to 100 observations by randomly selecting 100 observations from class A.\n",
    "\n",
    "#Up-sampling involves increasing the number of observations in the minority class to balance it with the majority class.\n",
    "#For example, if we have a dataset with 1000 observations and 100 of them belong to class A and 900 belong to class B, we can up-sample class A to 900 observations by replicating each observation in class A nine times.\n",
    "\n",
    "#When to use up-sampling or down-sampling depends on the nature of the dataset and the goals of the analysis. \n",
    "#If the minority class is important and we want to ensure that the model performs well on it, we might up-sample it. On the other hand, if the majority class is too large and it might overwhelm the model, we might down-sample it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add0f1f1-d26a-4d7c-a149-d4bd90ca91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5: What is data Augmentation? Explain SMOTE.\n",
    "#Ans.\n",
    "#Data augmentation is a technique used to increase the amount of training data by generating new examples from the existing data. \n",
    "#This technique can be useful in scenarios where the available data is limited or imbalanced.\n",
    "\n",
    "#SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used to address class imbalance by generating synthetic examples of the minority class. \n",
    "#For example, suppose we have a dataset with 1000 observations and only 100 of them belong to the minority class. \n",
    "#We can use SMOTE to generate new synthetic examples for the minority class by selecting one of the minority class observations and finding its k-nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759da922-7a60-4a43-86db-115d2709836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "#Ans.\n",
    "#Outliers are data points in a dataset that are significantly different from the other observations. \n",
    "#These data points can occur due to measurement errors, data entry errors, or genuine anomalies in the data.\n",
    "\n",
    "#It is essential to handle outliers in a dataset because they can have a significant impact on the analysis and the resulting model. \n",
    "#Outliers can skew the distribution of the data and affect the estimates of statistical measures such as mean and variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaae0410-4db0-47d3-8515-4aff5cf39f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "#Ans.\n",
    "#There are several techniques that can be used to handle missing data in an analysis. Some of them are:\n",
    "#Deletion: One technique is to delete the missing data.\n",
    "#Mean/Mode/Median Imputation: Another technique is to replace the missing data with the mean, mode, or median of the available data.\n",
    "#Regression Imputation: Regression imputation is a technique that involves using regression models to predict the missing data based on the available data.\n",
    "#Multiple Imputation: Multiple imputation is a technique that involves creating multiple imputed datasets and combining the results to obtain more accurate estimates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f519c77-807f-45ed-99c3-e7de7a497d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8: You are working with a large dataset and find that a small percentage of the data is missing. What aresome strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
    "#Ans.\n",
    "#Ther are several strategies that can be used to determine if the missing data is missing at random or if there is a pattern to the missing data. Some of them are:\n",
    "#Visual inspection: One approach is to plot the data and look for patterns.\n",
    "#Correlation analysis: Another approach is to calculate the correlation between the variables and check if there is a relationship between the missing data and the other variables.\n",
    "#Missing data tests: There are several statistical tests that can be used to check if the missing data is missing at random or not. \n",
    "#Imputation: Another strategy is to use imputation techniques to fill in the missing data and check if the imputed data matches the patterns of the available data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08541750-d3ff-460b-96d2-42eecb3f0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies youcan use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "#Ans.\n",
    "#When dealing with an imbalanced dataset, evaluating the performance of a machine learning model can be challenging. \n",
    "#Confusion matrix: A confusion matrix is a table that summarizes the performance of a classification model.\n",
    "#ROC curve and AUC: The Receiver Operating Characteristic (ROC) curve is a plot that shows the trade-off between sensitivity and specificity for different threshold values. \n",
    "#The Area Under the Curve (AUC) is a metric that summarizes the ROC curve.\n",
    "#Stratified k-fold cross-validation: In this technique, the dataset is split into k-folds, and the model is trained on k-1 folds and tested on the remaining fold. \n",
    "#Resampling techniques: Resampling techniques involve modifying the original dataset to create a balanced dataset. \n",
    "#Cost-sensitive learning: Cost-sensitive learning involves assigning different misclassification costs to different classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a4e137-158d-4c8d-a926-d0c6d7452476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset isunbalanced, with the bulk of customers reporting being satisfied. What methods can you employ tobalance the dataset and down-sample the majority class?\n",
    "#Ans.\n",
    "#When dealing with an imbalanced dataset with the majority class heavily outnumbering the minority class, one technique that can be used to balance the dataset is down-sampling the majority class. \n",
    "#Here are some methods to down-sample the majority class:Random under-sampling, Cluster-based under-sampling, Tomek links, NearMiss, Edited Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb14a06e-6f61-425a-ac7e-fde99b462a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on aproject that requires you to estimate the occurrence of a rare event. What methods can you employ tobalance the dataset and up-sample the minority class?\n",
    "#Ans.\n",
    "#When dealing with an imbalanced dataset with a minority class heavily outnumbered by the majority class, one technique that can be used to balance the dataset is up-sampling the minority class. \n",
    "#Here are some methods to up-sample the minority class:\n",
    "#Random over-sampling\n",
    "#Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "#Adaptive Synthetic Sampling (ADASYN)\n",
    "##Synthetic Minority Over-sampling Technique with Tree-based Inference (SMOTE-IT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd19aba-f442-41b4-8e02-4f5021f86d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
